{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c6dfd7c-4170-424e-b2e0-de38fd9d5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c20aab-335b-468d-af75-45250099b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/spam.csv'\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "messages = df['Message'].values.tolist()\n",
    "labels = df['Category'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94462763-5970-423c-b185-a44c3201c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[...,None].bool(),0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58ebd1-e7d1-4bb2-9836-254f13e95c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   2%|█▎                                                         | 4/175 [00:34<24:03,  8.44s/it]"
     ]
    }
   ],
   "source": [
    "def get_embeddings(texts,model,tokenizer,device,batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0,len(texts),batch_size), desc = \"Generating embeddings\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_texts_with_prefix = [f\"passage: {text}\" for text in batch_texts]\n",
    "        batch_dict = tokenizer(batch_texts_with_prefix, max_length = 512, padding = True, truncation = True)\n",
    "        batch_dict = {k: torch.tensor(v).to(device) for k,v in batch_dict.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "X_embeddings = get_embeddings(messages, model, tokenizer, device)\n",
    "metadata = [{\"index\":i,\"message\":message, \"label\": label, \"label_encoded\":y[i]} \n",
    "            for i,(message, label) in enumerate(zip(messages,labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "504b438a-7a89-4e2d-834a-78e11bd31e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "SEED = 42\n",
    "train_indices, test_indices = train_test_split(range(len(messages)),test_size = TEST_SIZE, stratify = y, random_state = SEED)\n",
    "X_train_emb = X_embeddings[train_indices]\n",
    "X_test_emb = X_embeddings[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "train_metadata = [metadata[i] for i in train_indices]\n",
    "test_metadata = [metadata[i] for i in test_indices]\n",
    "embedding_dim = X_train_emb.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(X_train_emb.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a9091c5-5721-4e67-b6f0-37d1621b9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_knn(query_text,model,tokenizer,device,index,train_metadata,k=1):\n",
    "    query_with_prefix = f\"query: {query_text}\"\n",
    "    batch_dict = tokenizer([query_with_prefix],max_length=512,padding=True,truncation=True)\n",
    "    batch_dict = {k:torch.tensor(v).to(device) for k,v in batch_dict.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "        query_embedding= average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "        query_embedding = F.normalize(query_embedding,p=2,dim=1)\n",
    "        query_embedding = query_embedding.cpu().numpy().astype(\"float32\")\n",
    "    scores, indices = index.search(query_embedding,k)\n",
    "    predictions= []\n",
    "    neighbor_info = []\n",
    "    for i in range(k):\n",
    "        neighbor_idx = indices[0][i]\n",
    "        neighbor_score = scores[0][i]\n",
    "        neighbor_label = train_metadata[neighbor_idx]['label']\n",
    "        neighbor_message = train_metadata[neighbor_idx]['message']\n",
    "        predictions.append(neighbor_label)\n",
    "        neighbor_info.append({\n",
    "            \"score\": float(neighbor_score),\n",
    "            \"label\": neighbor_label,\n",
    "            \"message\":neighbor_message[:100] + \"...\" if len(neighbor_message) > 100 else neighbor_message\n",
    "        })\n",
    "    unique_labels, counts = np.unique(predictions, return_counts = True)\n",
    "    final_prediction = unique_labels[np.argmax(counts)]\n",
    "    return final_prediction, neighbor_info         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59e2c5bf-d457-4c86-a174-f41285657914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn_accuracy(test_embeddings, test_labels, test_metadata, index, train_metadata, k_values=[1,3,5]):\n",
    "    results = {}\n",
    "    all_errors = {}\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = len(test_embeddings)\n",
    "        errors = []\n",
    "        for i in tqdm(range(total),desc=f\"Evaluating k={k}\"):\n",
    "            query_embedding = test_embeddings[i:i+1].astype(\"float32\")\n",
    "            true_label = test_metadata[i][\"label\"]\n",
    "            true_message = test_metadata[i][\"message\"]\n",
    "            scores, indices = index.search(query_embedding,k)\n",
    "            predictions = []\n",
    "            neighbor_details = []\n",
    "            for j in range(k):\n",
    "                neighbor_idx = indices[0][j]\n",
    "                neighbor_label = train_metadata[neighbor_idx][\"label\"]\n",
    "                neighbor_message = train_metadata[neighbor_idx][\"message\"]\n",
    "                neighbor_score = float(scores[0][j])\n",
    "                predictions.append(neighbor_label)\n",
    "                neighbor_details.append({\n",
    "                    \"label\": neighbor_label,\n",
    "                    \"message\": neighbor_message,\n",
    "                    \"score\":neighbor_score\n",
    "                })\n",
    "        unique_labels, counts = np.unique(predictions, return_counts=True)\n",
    "        predicted_label = unique_labels[np.argmax(counts)]\n",
    "\n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "        else:\n",
    "            error_info = {\n",
    "                \"index\" : i,\n",
    "                \"original_index\" : test_metadata[i][\"index\"],\n",
    "                \"message\" : true_message,\n",
    "                \"true_label\" : true_label,\n",
    "                \"predicted_label\" : predicted_label,\n",
    "                \"neighbors\" : neighbor_details,\n",
    "                \"label_distribution\" : {label: int(count) for label, count in zip(unique_labels,counts)}\n",
    "            }\n",
    "            errors.append(error_info)\n",
    "        accuracy = correct / total\n",
    "        error_count = total - correct\n",
    "        results[k] = accuracy\n",
    "        all_errors[k] = errors\n",
    "        print(f\"Accuracy with k = {k}: {accuracy:.4f}\")\n",
    "        print(f\"Number of errors with k = {k}: {error_count}/{total} ({(error_count/total)*100:.2f}%)\")\n",
    "    return results, all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae407b8d-4696-4aaa-acda-ca43147e99a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating accuracy on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=1: 100%|███████████████████████████████████████████████████████████████| 558/558 [00:01<00:00, 317.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 1: 0.0018\n",
      "Number of errors with k = 1: 557/558 (99.82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=3: 100%|███████████████████████████████████████████████████████████████| 558/558 [00:01<00:00, 327.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 3: 0.0018\n",
      "Number of errors with k = 3: 557/558 (99.82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=5: 100%|███████████████████████████████████████████████████████████████| 558/558 [00:01<00:00, 321.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 5: 0.0018\n",
      "Number of errors with k = 5: 557/558 (99.82%)\n",
      "\n",
      "==================================================\n",
      "ACCURACY RESULTS\n",
      "==================================================\n",
      "Top-1 accuracy: 0.0018 (0.18%)\n",
      "Top-3 accuracy: 0.0018 (0.18%)\n",
      "Top-5 accuracy: 0.0018 (0.18%)\n",
      "==================================================\n",
      "\n",
      "***Error analysis saved to: error_analysis.json***\n",
      "\n",
      "***Summary:\n",
      "k = 1: 0 errors out of 558 samples\n",
      "k = 3: 0 errors out of 558 samples\n",
      "k = 5: 0 errors out of 558 samples\n",
      "CPU times: total: 4.97 s\n",
      "Wall time: 5.23 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Evaluating accuracy on test set...\")\n",
    "accuracy_results, error_results = evaluate_knn_accuracy(X_test_emb,y_test,test_metadata,index, train_metadata, k_values=[1,3,5])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ACCURACY RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for k, accuracy in accuracy_results.items():\n",
    "    print(f\"Top-{k} accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "error_analysis = {\n",
    "    \"timestamp\" : datetime.now().isoformat(),\n",
    "    \"model\" : MODEL_NAME,\n",
    "    \"test_size\": len(X_test_emb),\n",
    "    \"accuracy_results\": accuracy_results,\n",
    "    \"errors_by_k\" : {}\n",
    "}\n",
    "for k, errors in error_results.items():\n",
    "    error_analysis[\"errors_by_k\"][f\"k_{k}\"] = {\n",
    "        \"total_errors\": len(errors),\n",
    "        \"error_rate\" : len(errors) / len(X_test_emb),\n",
    "        \"errors\" : errors\n",
    "    }\n",
    "output_file = \"error_analysis.json\"\n",
    "with open(output_file,\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(error_analysis, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\n***Error analysis saved to: {output_file}***\")\n",
    "print()\n",
    "print(f\"***Summary:\")\n",
    "for k, errors in error_results.items():\n",
    "    print(f\"k = {k}: {len(errors)} errors out of {len(X_test_emb)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f29a3c6e-1f6c-49c0-bb24-135a8a8105d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_classifier_pipeline(user_input, k = 3):\n",
    "    print()\n",
    "    print(f\"***Classifying: '{user_input}'\")\n",
    "    print()\n",
    "    print(f\"***Using top-{k} nearest neighbors\")\n",
    "    print()\n",
    "\n",
    "    prediction,neighbors = classify_with_knn(user_input, model, tokenizer, device, index, train_metadata,k=k)\n",
    "    print(f\"*** Prediction: {prediction.upper()}\")\n",
    "    print()\n",
    "\n",
    "    print(\"***Top neighbors:\")\n",
    "    for i, neighbor in enumerate(neighbors,1):\n",
    "        print(f\"{i}. Label {neighbor[\"label\"]} | Score: {neighbor['score']:.4f}\")\n",
    "        print(f\"Message: {neighbor[\"message\"]}\")\n",
    "        print()\n",
    "    labels = [n[\"label\"] for n in neighbors]\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"neighbors\" : neighbors,\n",
    "        \"label_distribution\": label_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "267d44a6-b922-40d7-8bb3-b31a3f47b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exxample 1: 'I am actually thinking a way of doing something useful' ---\n",
      "\n",
      "***Classifying: 'I am actually thinking a way of doing something useful'\n",
      "\n",
      "***Using top-3 nearest neighbors\n",
      "\n",
      "*** Prediction: HAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label ham | Score: 0.8424\n",
      "Message: yeah, that's what I was thinking\n",
      "\n",
      "2. Label ham | Score: 0.8412\n",
      "Message: that would be good … I'll phone you tomo lunchtime, shall I, to organise something?\n",
      "\n",
      "3. Label ham | Score: 0.8344\n",
      "Message: See? I thought it all through\n",
      "\n",
      "\n",
      "--- Exxample 2: 'FREE!! Click here to win $1000 NOW! Limited time offer' ---\n",
      "\n",
      "***Classifying: 'FREE!! Click here to win $1000 NOW! Limited time offer'\n",
      "\n",
      "***Using top-3 nearest neighbors\n",
      "\n",
      "*** Prediction: SPAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label spam | Score: 0.8575\n",
      "Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "2. Label spam | Score: 0.8575\n",
      "Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "3. Label spam | Score: 0.8468\n",
      "Message: URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to ...\n",
      "\n",
      "\n",
      "--- Interactive Tessting ---\n",
      "\n",
      "***Classifying: 'Win a free iPhone! Click here now!'\n",
      "\n",
      "***Using top-5 nearest neighbors\n",
      "\n",
      "*** Prediction: SPAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label spam | Score: 0.8633\n",
      "Message: FREE entry into our £250 weekly competition just text the word WIN to 80086 NOW. 18 T&C www.txttowin...\n",
      "\n",
      "2. Label spam | Score: 0.8604\n",
      "Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "3. Label spam | Score: 0.8604\n",
      "Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "4. Label spam | Score: 0.8511\n",
      "Message: U have won a nokia 6230 plus a free digital camera. This is what u get when u win our FREE auction. ...\n",
      "\n",
      "5. Label spam | Score: 0.8507\n",
      "Message: TheMob>Yo yo yo-Here comes a new selection of hot downloads for our members to get for FREE! Just cl...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_examples = [\"I am actually thinking a way of doing something useful\",\n",
    "                \"FREE!! Click here to win $1000 NOW! Limited time offer\"]\n",
    "for i, example in enumerate(test_examples,1):\n",
    "    print(f\"\\n--- Exxample {i}: '{example}' ---\")\n",
    "    resul = spam_classifier_pipeline(example, k = 3)\n",
    "print(\"\\n--- Interactive Tessting ---\")\n",
    "user_text = \"Win a free iPhone! Click here now!\"\n",
    "k_value = 5\n",
    "result = spam_classifier_pipeline(user_text, k = k_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
