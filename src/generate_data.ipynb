{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 1: Installation\n",
    "#!pip install -q --upgrade deep-translator pandas tqdm\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 2: Prepare Data Directory\n",
    "\n",
    "# S·ª≠ d·ª•ng Google Colab ƒë·ªÉ load nhanh d·ªØ li·ªáu\n",
    "\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu n√≥ ch∆∞a t·ªìn t·∫°i\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Th∆∞ m·ª•c /content/data ƒë√£ s·∫µn s√†ng.\")\n",
    "print(\"‚ÄºÔ∏è Vui l√≤ng k√©o v√† th·∫£ file 'spam.csv' c·ªßa b·∫°n v√†o th∆∞ m·ª•c n√†y ·ªü thanh b√™n tr√°i.\")"
   ],
   "id": "fd5f9f5448c77b81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3: Setup Optimized Functions\n",
    "\n",
    "# S·ª≠ d·ª•ng Google Colab ƒë·ªÉ load nhanh d·ªØ li·ªáu\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# ==========================================================\n",
    "# H√ÄM D·ªäCH B·ªÄN B·ªà (ROBUST BACK-TRANSLATION FUNCTION)\n",
    "# T·ª± ƒë·ªông th·ª≠ l·∫°i khi g·∫∑p l·ªói m·∫°ng ho·∫∑c b·ªã gi·ªõi h·∫°n t·ªëc ƒë·ªô.\n",
    "# ==========================================================\n",
    "def _back_translate_robust(sentence: str, source_lang: str = 'en', pivot_lang: str = 'vi', retries: int = 3, backoff_in_seconds: int = 5) -> str:\n",
    "    \"\"\"Th·ª±c hi·ªán back-translation cho m·ªôt c√¢u v·ªõi c∆° ch·∫ø th·ª≠ l·∫°i.\"\"\"\n",
    "    original_sentence = sentence\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            # D·ªãch xu√¥i (Anh -> Vi·ªát)\n",
    "            translated = GoogleTranslator(source=source_lang, target=pivot_lang).translate(sentence)\n",
    "            if not translated:\n",
    "                continue # N·∫øu d·ªãch ra r·ªóng, th·ª≠ l·∫°i\n",
    "\n",
    "            # D·ªãch ng∆∞·ª£c (Vi·ªát -> Anh)\n",
    "            back_translated = GoogleTranslator(source=pivot_lang, target=source_lang).translate(translated)\n",
    "\n",
    "            # Ch·ªâ tr·∫£ v·ªÅ c√¢u m·ªõi n·∫øu n√≥ th·ª±c s·ª± kh√°c c√¢u g·ªëc\n",
    "            if back_translated and back_translated.lower() != original_sentence.lower():\n",
    "                return back_translated\n",
    "\n",
    "            # N·∫øu kh√¥ng c√≥ g√¨ thay ƒë·ªïi, ch√∫ng ta kh√¥ng c·∫ßn c√¢u n√†y, tr·∫£ v·ªÅ None ƒë·ªÉ b·ªè qua\n",
    "            return None\n",
    "\n",
    "        except Exception as e:\n",
    "            # N·∫øu c√≥ l·ªói, ch·ªù m·ªôt ch√∫t r·ªìi th·ª≠ l·∫°i\n",
    "            print(f\"‚ö†Ô∏è L·ªói d·ªãch (l·∫ßn {i+1}/{retries}): {e}. ƒêang th·ª≠ l·∫°i sau {backoff_in_seconds} gi√¢y...\")\n",
    "            time.sleep(backoff_in_seconds)\n",
    "\n",
    "    # Tr·∫£ v·ªÅ None n·∫øu th·∫•t b·∫°i sau t·∫•t c·∫£ c√°c l·∫ßn th·ª≠\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# H√ÄM TƒÇNG C∆Ø·ªúNG D·ªÆ LI·ªÜU SONG SONG (PARALLEL AUGMENTATION)\n",
    "# ==========================================================\n",
    "def augment_data_parallel(input_path: str, message_col: str, label_col: str, max_workers: int = 64) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    T·∫£i d·ªØ li·ªáu, th·ª±c hi·ªán augmentation song song v√† tr·∫£ v·ªÅ DataFrame ƒë√£ c√¢n b·∫±ng.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh tƒÉng c∆∞·ªùng d·ªØ li·ªáu...\")\n",
    "    df = pd.read_csv(input_path, encoding='latin1') # D√πng encoding latin1 ph·ªï bi·∫øn cho dataset spam\n",
    "\n",
    "    # ƒê·ªïi t√™n c·ªôt cho nh·∫•t qu√°n n·∫øu c·∫ßn\n",
    "    df = df.rename(columns={df.columns[0]: label_col, df.columns[1]: message_col})\n",
    "    df = df[[label_col, message_col]].dropna()\n",
    "\n",
    "    print(\"\\nPh√¢n ph·ªëi nh√£n ban ƒë·∫ßu:\")\n",
    "    print(df[label_col].value_counts())\n",
    "\n",
    "    label_counts = Counter(df[label_col])\n",
    "    major_class_label, major_count = label_counts.most_common(1)[0]\n",
    "    minor_class_label, minor_count = label_counts.most_common()[-1]\n",
    "\n",
    "    if major_count == minor_count:\n",
    "        print(\"\\n‚úÖ D·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng. Kh√¥ng c·∫ßn augmentation.\")\n",
    "        return df\n",
    "\n",
    "    num_to_generate = major_count - minor_count\n",
    "    minority_messages = df[df[label_col] == minor_class_label][message_col].tolist()\n",
    "\n",
    "    print(f\"\\nC·∫ßn t·∫°o th√™m {num_to_generate} m·∫´u cho l·ªõp '{minor_class_label}'.\")\n",
    "\n",
    "    augmented_results = []\n",
    "\n",
    "    # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ ch·∫°y song song v·ªõi thanh ti·∫øn tr√¨nh tqdm\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # T·∫°o danh s√°ch c√°c t√°c v·ª•\n",
    "        futures = [executor.submit(_back_translate_robust, random.choice(minority_messages)) for _ in range(num_to_generate)]\n",
    "\n",
    "        # Thu th·∫≠p k·∫øt qu·∫£ khi ch√∫ng ho√†n th√†nh v√† hi·ªÉn th·ªã ti·∫øn tr√¨nh\n",
    "        for future in tqdm(as_completed(futures), total=num_to_generate, desc=\"T·ªïng h·ª£p c√¢u m·ªõi\"):\n",
    "            result = future.result()\n",
    "            if result: # Ch·ªâ th√™m v√†o n·∫øu k·∫øt qu·∫£ kh√¥ng ph·∫£i None\n",
    "                augmented_results.append(result)\n",
    "\n",
    "    print(f\"\\n‚ú® ƒê√£ t·∫°o th√†nh c√¥ng {len(augmented_results)} c√¢u m·ªõi ƒë·ªôc nh·∫•t.\")\n",
    "\n",
    "    # T·∫°o DataFrame t·ª´ d·ªØ li·ªáu m·ªõi v√† k·∫øt h·ª£p v·ªõi d·ªØ li·ªáu g·ªëc\n",
    "    df_new = pd.DataFrame({\n",
    "        label_col: [minor_class_label] * len(augmented_results),\n",
    "        message_col: augmented_results\n",
    "    })\n",
    "\n",
    "    df_augmented = pd.concat([df, df_new], ignore_index=True)\n",
    "\n",
    "    # Tr·ªôn ng·∫´u nhi√™n d·ªØ li·ªáu\n",
    "    df_augmented = df_augmented.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df_augmented\n",
    "\n",
    "print(\"‚úÖ C√°c h√†m t·ªëi ∆∞u ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\")"
   ],
   "id": "43e7f10cefb82f33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 4: Execute Augmentation and Save\n",
    "# S·ª≠ d·ª•ng Google Colab ƒë·ªÉ load nhanh d·ªØ li·ªáu\n",
    "\n",
    "INPUT_FILE_PATH = '/content/data/spam.csv'\n",
    "OUTPUT_FILE_PATH = '/content/spam_augmented.csv'\n",
    "\n",
    "# --- B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian ---\n",
    "start_time = time.time()\n",
    "\n",
    "# G·ªçi h√†m ch√≠nh ƒë·ªÉ th·ª±c hi·ªán c√¥ng vi·ªác\n",
    "df_final = augment_data_parallel(\n",
    "    input_path=INPUT_FILE_PATH,\n",
    "    message_col='Message', # T√™n c·ªôt tin nh·∫Øn\n",
    "    label_col='Category'   # T√™n c·ªôt nh√£n\n",
    ")\n",
    "\n",
    "# --- K·∫øt th√∫c ƒëo th·ªùi gian ---\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üèÅ QU√Å TR√åNH HO√ÄN T·∫§T üèÅ\")\n",
    "print(f\"T·ªïng th·ªùi gian th·ª±c thi: {elapsed_time:.2f} gi√¢y\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nPh√¢n ph·ªëi nh√£n sau khi augmentation:\")\n",
    "print(df_final['Category'].value_counts())\n",
    "\n",
    "# L∆∞u file k·∫øt qu·∫£\n",
    "df_final.to_csv(OUTPUT_FILE_PATH, index=False, encoding='utf-8')\n",
    "print(f\"\\n‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file: {OUTPUT_FILE_PATH}\")"
   ],
   "id": "bf239fd0a5cd7e3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 5: Download the Result\n",
    "# s·ª≠ d·ª•ng google colab ƒë·ªÉ load nhanh d·ªØ li·ªáu\n",
    "# from google.colab import files\n",
    "\n",
    "'''try:\n",
    "    files.download(OUTPUT_FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file '{OUTPUT_FILE_PATH}'. H√£y ch·∫Øc ch·∫Øn r·∫±ng √¥ tr∆∞·ªõc ƒë√£ ch·∫°y th√†nh c√¥ng.\")'''"
   ],
   "id": "4cb6a19f2f07de83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
